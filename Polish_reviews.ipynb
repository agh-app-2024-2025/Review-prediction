{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# imports and functions"
      ],
      "metadata": {
        "id": "hknJTfuC-rHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, GRU, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.metrics import MeanAbsoluteError\n",
        "from tensorflow.keras.losses import MAE\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score,  r2_score, f1_score, classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import joblib"
      ],
      "metadata": {
        "id": "LKdQ5rW6-PU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show(df):\n",
        "  df['Rating'].plot(kind='hist', bins=20, title='Rating')\n",
        "  plt.gca().spines[['top', 'right',]].set_visible(False)\n",
        "  df.info()"
      ],
      "metadata": {
        "id": "ebEMTqQZ-NqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_accuracy(y_true, y_pred):\n",
        "    tolerance = 0.5\n",
        "    return np.mean(np.abs(y_true - y_pred) <= tolerance)"
      ],
      "metadata": {
        "id": "w02BgHuL-dtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_review_rating(review_text, tok_name, model_name):\n",
        "    tokenizer = joblib.load(f'{tok_name}.pkl')\n",
        "    model = load_model(f'{model_name}.h5', custom_objects={'mse': metrics.MeanSquaredError})\n",
        "\n",
        "    review_sequence = tokenizer.texts_to_sequences([review_text])\n",
        "    review_padded = pad_sequences(review_sequence, maxlen=500)\n",
        "\n",
        "    predicted_rating = model.predict(review_padded)\n",
        "    return round(predicted_rating[0][0], 2)"
      ],
      "metadata": {
        "id": "AWrefmQo-heY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenization with our own solution (for research topic)\n",
        "\n",
        "class SimpleTokenizer:\n",
        "    def __init__(self, num_words=None):\n",
        "        self.num_words = num_words\n",
        "        self.word_index = {}\n",
        "        self.index_word = {}\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        word_counts = defaultdict(int)\n",
        "        for text in texts:\n",
        "            for word in text.split():\n",
        "                word_counts[word] += 1\n",
        "\n",
        "        sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "        if self.num_words:\n",
        "            sorted_words = sorted_words[:self.num_words - 1]\n",
        "\n",
        "        self.word_index = {word: i + 1 for i, (word, _) in enumerate(sorted_words)}\n",
        "        self.index_word = {i: word for word, i in self.word_index.items()}\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        sequences = []\n",
        "        for text in texts:\n",
        "            sequences.append([self.word_index.get(word, 0) for word in text.split()])\n",
        "        return sequences\n",
        "\n",
        "    def pad_sequences(self, sequences, maxlen):\n",
        "        padded_sequences = np.zeros((len(sequences), maxlen), dtype=int)\n",
        "        for i, seq in enumerate(sequences):\n",
        "            if len(seq) > maxlen:\n",
        "                padded_sequences[i, :] = seq[:maxlen]\n",
        "            else:\n",
        "                padded_sequences[i, -len(seq):] = seq\n",
        "        return padded_sequences"
      ],
      "metadata": {
        "id": "sxjcS33ytZ-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Benchmark models\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8cUsvnBP-umb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run(data, tok_name = 'tokenizer', model_name = 'model', save = False):\n",
        "  tokenizer = Tokenizer(num_words=5000)\n",
        "  tokenizer.fit_on_texts(data['Review'])\n",
        "  X = tokenizer.texts_to_sequences(data['Review'])\n",
        "  X = pad_sequences(X, maxlen=500)\n",
        "  y = data['Rating'].values\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=5000, output_dim=128, input_length=500))\n",
        "  model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "  model.add(Dense(1, activation='linear'))\n",
        "\n",
        "  model.compile(optimizer='adam', loss='mse', metrics=['accuracy','mae'])\n",
        "  history = model.fit(X_train, y_train, epochs=3, batch_size=64, validation_split=0.1)\n",
        "\n",
        "  y_pred = model.predict(X_test).flatten()\n",
        "\n",
        "  y_test_classes = np.digitize(y_test, bins = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]) - 1\n",
        "  y_pred_classes = np.digitize(y_pred, bins = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]) - 1\n",
        "\n",
        "  f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')\n",
        "  mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "  loss, accuracy, mae_evaluate = model.evaluate(X_test, y_test)\n",
        "  acc = custom_accuracy(y_test, y_pred)\n",
        "  print('1 - benchmark')\n",
        "  print(f'MAE on Test Set: {mae}')\n",
        "  print(f'MAE_ev on Test Set: {mae_evaluate}')\n",
        "  print(f'Accuracy on Test Set: {accuracy}')\n",
        "  print(f'F1 Score on Test Set: {f1:.2f}')\n",
        "  print(f'Custom Accuracy (within tolerance): {acc * 100:.2f}%')\n",
        "\n",
        "  if save:\n",
        "    joblib.dump(tokenizer, f'{tok_name}.pkl')\n",
        "    model.save(f'{model_name}.h5')"
      ],
      "metadata": {
        "id": "F66ygSop-Fhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run2(data, tok_name='tokenizer', model_name='model', save=False):\n",
        "    tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts(data['Review'])\n",
        "    X = tokenizer.texts_to_sequences(data['Review'])\n",
        "    X = pad_sequences(X, maxlen=500)\n",
        "    y = data['Rating'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=5000, output_dim=128, input_length=500),\n",
        "        LSTM(64, dropout=0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='relu')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mae', metrics=['accuracy','mae'])\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=20, batch_size=64,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[early_stop]\n",
        "    )\n",
        "\n",
        "    y_pred = model.predict(X_test).flatten()\n",
        "\n",
        "    y_test_classes = np.digitize(y_test, bins = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]) - 1\n",
        "    y_pred_classes = np.digitize(y_pred, bins = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]) - 1\n",
        "\n",
        "    f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    loss, accuracy, mae_evaluate = model.evaluate(X_test, y_test)\n",
        "    acc = custom_accuracy(y_test, y_pred)\n",
        "    print('2 - benchmark')\n",
        "    print(f'MAE on Test Set: {mae}')\n",
        "    print(f'MAE_ev on Test Set: {mae_evaluate}')\n",
        "    print(f'Accuracy on Test Set: {accuracy}')\n",
        "    print(f'F1 Score on Test Set: {f1:.2f}')\n",
        "    print(f'Custom Accuracy (within tolerance): {acc * 100:.2f}%')\n",
        "\n",
        "    if save:\n",
        "      joblib.dump(tokenizer, f'{tok_name}.pkl')\n",
        "      model.save(f'{model_name}.h5')\n",
        "\n",
        "    return model, history\n"
      ],
      "metadata": {
        "id": "rPWSH92_-IkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Benchmark models with integer outputs"
      ],
      "metadata": {
        "id": "MO4_-T0jaPTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_int(data, tok_name='tokenizer', model_name='model', save=False):\n",
        "    tokenizer = Tokenizer(num_words=5000)\n",
        "    tokenizer.fit_on_texts(data['Review'])\n",
        "    X = tokenizer.texts_to_sequences(data['Review'])\n",
        "    X = pad_sequences(X, maxlen=500)\n",
        "    y = data['Rating'].values - 1\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=5000, output_dim=128, input_length=500))\n",
        "    model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(X_train, y_train, epochs=3, batch_size=64, validation_split=0.1)\n",
        "\n",
        "    y_pred_classes = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "    f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "    print('1 na int')\n",
        "    print(f'F1 Score on Test Set: {f1:.2f}')\n",
        "    print(f'Accuracy on Test Set: {accuracy:.2f}')\n",
        "\n",
        "    if save:\n",
        "        joblib.dump(tokenizer, f'{tok_name}.pkl')\n",
        "        model.save(f'{model_name}.h5')\n"
      ],
      "metadata": {
        "id": "zthFYH6BDKVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run2_int(data, tok_name='tokenizer', model_name='model', save=False):\n",
        "    tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts(data['Review'])\n",
        "    X = tokenizer.texts_to_sequences(data['Review'])\n",
        "    X = pad_sequences(X, maxlen=500)\n",
        "\n",
        "    y = data['Rating'].values - 1\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=5000, output_dim=128, input_length=500),\n",
        "        LSTM(64, dropout=0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=20, batch_size=64,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[early_stop]\n",
        "    )\n",
        "\n",
        "    y_pred_probs = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "    f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "    print('2 na int')\n",
        "    print(f'Accuracy on Test Set: {accuracy}')\n",
        "    print(f'F1 Score on Test Set: {f1:.2f}')\n",
        "\n",
        "    if save:\n",
        "        joblib.dump(tokenizer, f'{tok_name}.pkl')\n",
        "        model.save(f'{model_name}.h5')\n",
        "\n",
        "    return model, history\n"
      ],
      "metadata": {
        "id": "gwrSzuIzFfXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run2_bi(data, tok_name='tokenizer', model_name='model', save=False):\n",
        "    tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts(data['Review'])\n",
        "    X = tokenizer.texts_to_sequences(data['Review'])\n",
        "    X = pad_sequences(X, maxlen=500)\n",
        "\n",
        "    y = data['Rating'].values - 1\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = Sequential([\n",
        "      Embedding(input_dim=10000, output_dim=128, input_length=500),\n",
        "      Bidirectional(LSTM(128, dropout=0.2, return_sequences=True)),\n",
        "      LSTM(64, dropout=0.2),\n",
        "      Dense(64, activation='relu'),\n",
        "      Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=20, batch_size=64,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[early_stop]\n",
        "    )\n",
        "\n",
        "    y_pred_probs = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "    f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "    print('Bi')\n",
        "    print(f'Accuracy on Test Set: {accuracy}')\n",
        "    print(f'F1 Score on Test Set: {f1:.2f}')\n",
        "\n",
        "    if save:\n",
        "        joblib.dump(tokenizer, f'{tok_name}.pkl')\n",
        "        model.save(f'{model_name}.h5')\n",
        "\n",
        "    return model, history\n"
      ],
      "metadata": {
        "id": "p288JXk4Ls4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRU"
      ],
      "metadata": {
        "id": "Mic4dOKjaL5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run2_gru(data, tok_name='tokenizer', model_name='model', save=False):\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts(data['Review'])\n",
        "    X = tokenizer.texts_to_sequences(data['Review'])\n",
        "    X = pad_sequences(X, maxlen=500)\n",
        "\n",
        "\n",
        "    y = data['Rating'].values - 1\n",
        "\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=5000, output_dim=128, input_length=500),\n",
        "        GRU(128, dropout=0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=20, batch_size=64,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[early_stop]\n",
        "    )\n",
        "\n",
        "    y_pred_probs = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "    f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "    print('GRU')\n",
        "    print(f'Accuracy on Test Set: {accuracy}')\n",
        "    print(f'F1 Score on Test Set: {f1:.2f}')\n",
        "\n",
        "    if save:\n",
        "        joblib.dump(tokenizer, f'{tok_name}.pkl')\n",
        "        model.save(f'{model_name}.h5')\n",
        "\n",
        "    return model, history\n"
      ],
      "metadata": {
        "id": "HmA3-tCIadWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN + RNN hybrid"
      ],
      "metadata": {
        "id": "rMOyMIqKXm8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run2_cnn_rnn(data, tok_name='tokenizer', model_name='model', save=False):\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts(data['Review'])\n",
        "    X = tokenizer.texts_to_sequences(data['Review'])\n",
        "    X = pad_sequences(X, maxlen=500)\n",
        "\n",
        "    y = data['Rating'].values - 1\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=5000, output_dim=128, input_length=500),\n",
        "        Conv1D(128, kernel_size=5, activation='relu'),\n",
        "        MaxPooling1D(pool_size=4),\n",
        "        LSTM(64, dropout=0.2, return_sequences=False),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=20, batch_size=64,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[early_stop]\n",
        "    )\n",
        "\n",
        "    y_pred_probs = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "    f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "    print('cnn+rnn')\n",
        "    print(f'Accuracy on Test Set: {accuracy}')\n",
        "    print(f'F1 Score on Test Set: {f1:.2f}')\n",
        "\n",
        "    if save:\n",
        "        joblib.dump(tokenizer, f'{tok_name}.pkl')\n",
        "        model.save(f'{model_name}.h5')\n",
        "\n",
        "    return model, history\n"
      ],
      "metadata": {
        "id": "lUy95bNOXqjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVC"
      ],
      "metadata": {
        "id": "NZo1Rc4dXeL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run2_svm(data, vectorizer_name='tfidf_vectorizer', model_name='svm_model', save=False):\n",
        "\n",
        "    reviews = data['Review'].tolist()\n",
        "    ratings = data['Rating'].values - 1\n",
        "\n",
        "    vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "    X = vectorizer.fit_transform(reviews).toarray()\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = SVC(kernel='linear', C=1, probability=True)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    print('SVC')\n",
        "    print(f'Accuracy on Test Set: {accuracy}')\n",
        "    print(f'F1 Score on Test Set: {f1:.2f}')\n",
        "\n",
        "    if save:\n",
        "        joblib.dump(vectorizer, f'{vectorizer_name}.pkl')\n",
        "        joblib.dump(model, f'{model_name}.pkl')\n",
        "\n",
        "    return model, vectorizer\n"
      ],
      "metadata": {
        "id": "RuCNsJVtXfxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LogisticRegression"
      ],
      "metadata": {
        "id": "Y1fwYP830TWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_logistic_regression(data, target_col='Rating', text_col='Review', save=False, model_name='logistic_model'):\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(data[target_col])\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        data[text_col], y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('vectorizer', CountVectorizer(max_features=5000, stop_words='english')),\n",
        "        ('classifier', LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42))\n",
        "    ])\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    print(\"run_logistic_regression\")\n",
        "    print(f'Accuracy: {acc}')\n",
        "    print(f'F1 Score: {f1:.2f}')\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    if save:\n",
        "        joblib.dump(pipeline, f'{model_name}.pkl')\n",
        "        joblib.dump(label_encoder, f'{model_name}_label_encoder.pkl')\n",
        "\n",
        "    return pipeline, label_encoder\n"
      ],
      "metadata": {
        "id": "JfE1AuI40WdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# run all"
      ],
      "metadata": {
        "id": "lUA88mEG2jlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/temp4.csv')"
      ],
      "metadata": {
        "id": "xmFFsQ5Z3wHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_data = (\n",
        "    df.groupby('Rating', group_keys=False)\n",
        "    .apply(lambda x: x.sample(n=3000, random_state=42) if len(x) >= 3000 else x)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfplU73I32hN",
        "outputId": "0f4297cd-846d-4ea4-ed49-205a673915fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-9a4fffe4ca1c>:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda x: x.sample(n=3000, random_state=42) if len(x) >= 3000 else x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show(sampled_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "d1roz5lIAAII",
        "outputId": "17608597-00bb-4d6a-a7a9-824704945afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 28885 entries, 4 to 24390\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Unnamed: 0.1  28885 non-null  int64  \n",
            " 1   Unnamed: 0    23355 non-null  float64\n",
            " 2   Title         22053 non-null  object \n",
            " 3   URL           22053 non-null  object \n",
            " 4   Review        28885 non-null  object \n",
            " 5   Rating        28885 non-null  float64\n",
            "dtypes: float64(2), int64(1), object(3)\n",
            "memory usage: 1.5+ MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run(sampled_data, \"tokenizer_clean\", \"model_clean\", False)"
      ],
      "metadata": {
        "id": "xWObG-JJ-owv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1df09d8b-fba8-432d-eb07-91899ffaa524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 649ms/step - accuracy: 0.0702 - loss: 12.7801 - mae: 2.9039 - val_accuracy: 0.0775 - val_loss: 4.4447 - val_mae: 1.6861\n",
            "Epoch 2/3\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 644ms/step - accuracy: 0.0807 - loss: 3.8672 - mae: 1.5686 - val_accuracy: 0.0775 - val_loss: 3.0964 - val_mae: 1.3910\n",
            "Epoch 3/3\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 639ms/step - accuracy: 0.0803 - loss: 2.6283 - mae: 1.2850 - val_accuracy: 0.0775 - val_loss: 2.7163 - val_mae: 1.2986\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 87ms/step\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.0730 - loss: 2.9429 - mae: 1.3573\n",
            "1 - benchmark\n",
            "MAE on Test Set: 1.350948469210026\n",
            "MAE_ev on Test Set: 1.3509485721588135\n",
            "Accuracy on Test Set: 0.07564479857683182\n",
            "F1 Score on Test Set: 0.21\n",
            "Custom Accuracy (within tolerance): 22.88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run2(sampled_data, \"tokenizer_clean\", \"model_clean\", False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CISdR-GJr5Q9",
        "outputId": "48131374-2775-4665-88e0-ef3366f13ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 627ms/step - accuracy: 0.0726 - loss: 2.8655 - mae: 2.8655 - val_accuracy: 0.0775 - val_loss: 1.7444 - val_mae: 1.7444\n",
            "Epoch 2/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 630ms/step - accuracy: 0.0872 - loss: 1.5241 - mae: 1.5241 - val_accuracy: 0.0775 - val_loss: 1.3460 - val_mae: 1.3460\n",
            "Epoch 3/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 624ms/step - accuracy: 0.0843 - loss: 1.2328 - mae: 1.2328 - val_accuracy: 0.0775 - val_loss: 1.2938 - val_mae: 1.2938\n",
            "Epoch 4/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 628ms/step - accuracy: 0.0808 - loss: 1.0988 - mae: 1.0988 - val_accuracy: 0.0775 - val_loss: 1.2358 - val_mae: 1.2358\n",
            "Epoch 5/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 628ms/step - accuracy: 0.0793 - loss: 0.9810 - mae: 0.9810 - val_accuracy: 0.0775 - val_loss: 1.2158 - val_mae: 1.2158\n",
            "Epoch 6/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 642ms/step - accuracy: 0.0865 - loss: 0.9101 - mae: 0.9101 - val_accuracy: 0.0775 - val_loss: 1.2082 - val_mae: 1.2082\n",
            "Epoch 7/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 631ms/step - accuracy: 0.0805 - loss: 0.8296 - mae: 0.8296 - val_accuracy: 0.0775 - val_loss: 1.1954 - val_mae: 1.1954\n",
            "Epoch 8/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 623ms/step - accuracy: 0.0837 - loss: 0.7923 - mae: 0.7923 - val_accuracy: 0.0775 - val_loss: 1.1881 - val_mae: 1.1881\n",
            "Epoch 9/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 612ms/step - accuracy: 0.0792 - loss: 0.7602 - mae: 0.7602 - val_accuracy: 0.0775 - val_loss: 1.1913 - val_mae: 1.1913\n",
            "Epoch 10/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 632ms/step - accuracy: 0.0767 - loss: 0.7062 - mae: 0.7062 - val_accuracy: 0.0775 - val_loss: 1.1919 - val_mae: 1.1919\n",
            "Epoch 11/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 633ms/step - accuracy: 0.0776 - loss: 0.6752 - mae: 0.6752 - val_accuracy: 0.0775 - val_loss: 1.1750 - val_mae: 1.1750\n",
            "Epoch 12/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 726ms/step - accuracy: 0.0812 - loss: 0.6578 - mae: 0.6578 - val_accuracy: 0.0775 - val_loss: 1.2038 - val_mae: 1.2038\n",
            "Epoch 13/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 657ms/step - accuracy: 0.0846 - loss: 0.6314 - mae: 0.6314 - val_accuracy: 0.0775 - val_loss: 1.1815 - val_mae: 1.1815\n",
            "Epoch 14/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 637ms/step - accuracy: 0.0835 - loss: 0.6098 - mae: 0.6098 - val_accuracy: 0.0775 - val_loss: 1.1855 - val_mae: 1.1855\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.0730 - loss: 1.2169 - mae: 1.2169\n",
            "2 - benchmark\n",
            "MAE on Test Set: 1.2033021069943173\n",
            "MAE_ev on Test Set: 1.203302264213562\n",
            "Accuracy on Test Set: 0.07564479857683182\n",
            "F1 Score on Test Set: 0.31\n",
            "Custom Accuracy (within tolerance): 31.80%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Sequential name=sequential_9, built=True>,\n",
              " <keras.src.callbacks.history.History at 0x78fca07eece0>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_int(sampled_data, \"tokenizer_clean\", \"model_clean\", False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaGaXk0ZDN-Z",
        "outputId": "d8f1bf7c-be8e-454e-f9f6-7354a4b05573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 649ms/step - accuracy: 0.1676 - loss: 2.1619 - val_accuracy: 0.2627 - val_loss: 1.8241\n",
            "Epoch 2/3\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 649ms/step - accuracy: 0.3016 - loss: 1.7474 - val_accuracy: 0.3289 - val_loss: 1.7128\n",
            "Epoch 3/3\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 643ms/step - accuracy: 0.3820 - loss: 1.5694 - val_accuracy: 0.3531 - val_loss: 1.6447\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step\n",
            "1 na int\n",
            "F1 Score on Test Set: 0.33\n",
            "Accuracy on Test Set: 0.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run2_int(sampled_data, \"tokenizer_clean\", \"model_clean\", False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsUu7YntFjbi",
        "outputId": "1d021edd-126f-4635-94cc-0a0d36cfb773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 622ms/step - accuracy: 0.1534 - loss: 2.1881 - val_accuracy: 0.2523 - val_loss: 1.8542\n",
            "Epoch 2/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 623ms/step - accuracy: 0.2966 - loss: 1.7334 - val_accuracy: 0.2717 - val_loss: 1.7521\n",
            "Epoch 3/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 629ms/step - accuracy: 0.3517 - loss: 1.5812 - val_accuracy: 0.3367 - val_loss: 1.6608\n",
            "Epoch 4/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 635ms/step - accuracy: 0.4222 - loss: 1.4244 - val_accuracy: 0.3527 - val_loss: 1.6886\n",
            "Epoch 5/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 621ms/step - accuracy: 0.4784 - loss: 1.2763 - val_accuracy: 0.3890 - val_loss: 1.6510\n",
            "Epoch 6/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 618ms/step - accuracy: 0.5388 - loss: 1.1644 - val_accuracy: 0.3868 - val_loss: 1.6845\n",
            "Epoch 7/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 621ms/step - accuracy: 0.5626 - loss: 1.1028 - val_accuracy: 0.3959 - val_loss: 1.7334\n",
            "Epoch 8/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 617ms/step - accuracy: 0.6201 - loss: 0.9760 - val_accuracy: 0.3946 - val_loss: 1.7764\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step\n",
            "2 na int\n",
            "Accuracy on Test Set: 0.36247187121343255\n",
            "F1 Score on Test Set: 0.35\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Sequential name=sequential_11, built=True>,\n",
              " <keras.src.callbacks.history.History at 0x78fca07ffca0>)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run2_bi(sampled_data, \"tokenizer_clean\", \"model_clean\", False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiVtK0IBMPqf",
        "outputId": "56db0226-33ba-4d82-b2c2-47cadc53c54d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1109s\u001b[0m 3s/step - accuracy: 0.1657 - loss: 2.1370 - val_accuracy: 0.2761 - val_loss: 1.7827\n",
            "Epoch 2/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1166s\u001b[0m 3s/step - accuracy: 0.3348 - loss: 1.6116 - val_accuracy: 0.2873 - val_loss: 1.7409\n",
            "Epoch 3/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1116s\u001b[0m 3s/step - accuracy: 0.4064 - loss: 1.4265 - val_accuracy: 0.3271 - val_loss: 1.7178\n",
            "Epoch 4/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1113s\u001b[0m 3s/step - accuracy: 0.4845 - loss: 1.2640 - val_accuracy: 0.3315 - val_loss: 1.8139\n",
            "Epoch 5/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1167s\u001b[0m 3s/step - accuracy: 0.5376 - loss: 1.1349 - val_accuracy: 0.3739 - val_loss: 1.8107\n",
            "Epoch 6/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1115s\u001b[0m 3s/step - accuracy: 0.5867 - loss: 1.0103 - val_accuracy: 0.3583 - val_loss: 1.9302\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 694ms/step\n",
            "Bi\n",
            "Accuracy on Test Set: 0.34066124285961574\n",
            "F1 Score on Test Set: 0.33\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Sequential name=sequential, built=True>,\n",
              " <keras.src.callbacks.history.History at 0x7eab0419fc10>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run2_gru(sampled_data, \"tokenizer_clean\", \"model_clean\", False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TViO61P_arXH",
        "outputId": "e45c97be-ab11-4bbb-f3c1-3aa839f9482e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 1s/step - accuracy: 0.1448 - loss: 2.2022 - val_accuracy: 0.2852 - val_loss: 1.7893\n",
            "Epoch 2/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 1s/step - accuracy: 0.2967 - loss: 1.7251 - val_accuracy: 0.3120 - val_loss: 1.7481\n",
            "Epoch 3/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 1s/step - accuracy: 0.4027 - loss: 1.5040 - val_accuracy: 0.3388 - val_loss: 1.6413\n",
            "Epoch 4/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 1s/step - accuracy: 0.4932 - loss: 1.2993 - val_accuracy: 0.3527 - val_loss: 1.6726\n",
            "Epoch 5/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 1s/step - accuracy: 0.5507 - loss: 1.1547 - val_accuracy: 0.3682 - val_loss: 1.6995\n",
            "Epoch 6/20\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 1s/step - accuracy: 0.6205 - loss: 1.0136 - val_accuracy: 0.3756 - val_loss: 1.7705\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 144ms/step\n",
            "GRU\n",
            "Accuracy on Test Set: 0.3410074433096763\n",
            "F1 Score on Test Set: 0.33\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Sequential name=sequential_1, built=True>,\n",
              " <keras.src.callbacks.history.History at 0x7eaa6ed974c0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run2_cnn_rnn(sampled_data, \"tokenizer_clean\", \"model_clean\", False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzUvv7tSYw7u",
        "outputId": "6d2740bd-a83c-4c42-becd-505aeeada4f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 610ms/step - accuracy: 0.1017 - loss: 2.2986 - val_accuracy: 0.1750 - val_loss: 2.1235\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 600ms/step - accuracy: 0.1942 - loss: 2.0056 - val_accuracy: 0.2125 - val_loss: 1.8621\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 582ms/step - accuracy: 0.2958 - loss: 1.6860 - val_accuracy: 0.2800 - val_loss: 1.8270\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 604ms/step - accuracy: 0.3707 - loss: 1.4829 - val_accuracy: 0.2587 - val_loss: 1.8663\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 582ms/step - accuracy: 0.4557 - loss: 1.3092 - val_accuracy: 0.2775 - val_loss: 1.9840\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 590ms/step - accuracy: 0.5299 - loss: 1.1747 - val_accuracy: 0.2763 - val_loss: 2.1484\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 602ms/step - accuracy: 0.5490 - loss: 1.0857 - val_accuracy: 0.2713 - val_loss: 2.4133\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 588ms/step - accuracy: 0.6053 - loss: 0.9571 - val_accuracy: 0.2688 - val_loss: 2.7198\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step\n",
            "Accuracy on Test Set: 0.2425\n",
            "F1 Score on Test Set: 0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Sequential name=sequential_1, built=True>,\n",
              " <keras.src.callbacks.history.History at 0x7b009e82cd60>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run2_svm(sampled_data, \"tokenizer_clean\", \"model_clean\", False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUrm3lz3dVYj",
        "outputId": "9e50a9a0-5080-46dd-ccfb-66cb8e6158d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Test Set: 0.2925\n",
            "F1 Score on Test Set: 0.29\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(SVC(C=1, kernel='linear', probability=True),\n",
              " TfidfVectorizer(max_features=5000, stop_words='english'))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline, label_encoder = run_logistic_regression(sampled_data, save = True,  model_name='logistic_model_pl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP6dPgsi2cfD",
        "outputId": "f3352612-394e-4595-e2ef-fb1f89f70180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run_logistic_regression\n",
            "Accuracy: 0.38462870001731003\n",
            "F1 Score: 0.38\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.83      0.78       437\n",
            "           1       0.69      0.75      0.72       566\n",
            "           2       0.47      0.45      0.46       562\n",
            "           3       0.43      0.40      0.42       635\n",
            "           4       0.32      0.30      0.31       594\n",
            "           5       0.26      0.26      0.26       612\n",
            "           6       0.17      0.19      0.18       565\n",
            "           7       0.21      0.20      0.21       618\n",
            "           8       0.27      0.25      0.26       612\n",
            "           9       0.34      0.35      0.35       576\n",
            "\n",
            "    accuracy                           0.38      5777\n",
            "   macro avg       0.39      0.40      0.39      5777\n",
            "weighted avg       0.38      0.38      0.38      5777\n",
            "\n"
          ]
        }
      ]
    }
  ]
}